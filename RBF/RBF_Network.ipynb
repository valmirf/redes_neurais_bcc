{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RBF Network",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valmirf/redes_neurais_bcc/blob/main/RBF/RBF_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A0GQWDGtrpX"
      },
      "source": [
        "# Rede Neural de Base Radial (RBF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7W_VNPAkFcO"
      },
      "source": [
        "As redes RBF são redes de alimentação direta (feedforward) consistindo de três camadas:\n",
        "\n",
        "\n",
        "1.   **Camada de entrada**: propaga os estímulos\n",
        "2.   **Camada escondida**: Unidades de processamento localmente sintonizáveis, utilizando mapeamento não linear.\n",
        "3.   **Camada de saída**: Unidades de processamento lineares.\n",
        "\n",
        "\n",
        "****\n",
        "\n",
        "**O treinamento dessa rede ocorre de forma híbrida**, combinando aprendizagem não supervisionada (ANS) com a supervisionada(AS). Isso ocorre, pois em geral não se sabe quais saídas se desejam para a camada escondida. Sendo assim, a distribuição de trabalhos ocorre:\n",
        "*   **ANS**: Treina a camada escondida definindo seus parâmetros livres (centros, larguras dos campos receptivos e pesos).\n",
        "*   **AS**: Determina os valores dos pesos entre as camadas escondidas e de saída, considerando constantes os parâmetros já definidos.\n",
        "\n",
        "\n",
        "****\n",
        "\n",
        "**O aprendizado consiste em** determinar os valores para:\n",
        "*   centro das funções de base radial,\n",
        "*   largura das funções,\n",
        "*   pesos da camada de saída.\n",
        "\n",
        "\n",
        "Além disso, para cada neurônio da camada escondida, ele computa uma função de base radial.\n",
        "\n",
        "\n",
        "Os passos necessários são:\n",
        "1.   Utilizar um algoritmo ANS para encontrar os centros (protótipo para um cluster) das RBF;\n",
        "2.   Utilizar métodos heurísticos para determinar a largura (área de influência de um cluster) de cada função;\n",
        "3.   Utilizar um AS para determinar os pesos da camada de saída da rede."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOIor4J3PFBL"
      },
      "source": [
        "1ª Etapa: Inicialização dos grupos com K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHWuP3AXjvq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5165baf-9ae6-4f92-998f-60d9413a6b44"
      },
      "source": [
        "!git clone https://github.com/valmirf/redes_neurais_bcc.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'redes_neurais_bcc'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 19 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (19/19), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ulVaA8RPSwo"
      },
      "source": [
        "Definição da função de base radial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeqYYe9hPY4v"
      },
      "source": [
        "#função de base radial gaussiana\n",
        "def rbfGaussiana(x, c, s):\n",
        "    return np.exp(-1 / (2 * s**2) * (x-c)**2)\n",
        "\n",
        "#função de cálculo da largura do campo receptivo em que se repete o mesmo valor pra todos os neurônios\n",
        "def computeEqualStds(centers,k):\n",
        "  dist = [np.sqrt(np.sum((c1 - c2) ** 2)) for c1 in centers for c2 in centers]\n",
        "  dMax = np.max(dist)\n",
        "  stds = np.repeat(dMax / np.sqrt(2 * k), k)\n",
        "  return stds"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkrFhNWPLq41"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52oUNimoPuK3"
      },
      "source": [
        "2ª Etapa - Treinamento de uma Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGdrOhYfPzBu"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "class RBFNet(object):\n",
        "    \"\"\"Implementation of a Radial Basis Function Network\"\"\"\n",
        "\n",
        "    def __init__(self, k=3, attnumber=4, lr=0.01, epochs=100, rbf=rbfGaussiana, computeStds=computeEqualStds):\n",
        "        self.k = k  # grupos ou numero de neuronios na camada escondida\n",
        "        self.lr = lr # taxa de aprendizagem\n",
        "        self.epochs = epochs  # número de iterações\n",
        "        self.rbf = rbf # função de base radial\n",
        "        self.computeStds = computeStds  #função de cálculo da largura do campo receptivo\n",
        "\n",
        "        self.w = np.random.randn(self.k,attnumber)\n",
        "        self.b = np.random.randn(1)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.stds = []\n",
        "        #K-Means pra pegar os centros inicias \n",
        "        #1º parâmetro da rede RBF\n",
        "        kmeans = KMeans(\n",
        "            n_clusters=self.k, init='random',\n",
        "            n_init=10, max_iter=300).fit(X)\n",
        "        self.centers = kmeans.cluster_centers_\n",
        "        #print('centers: ', self.centers)\n",
        "        \n",
        "        #Cálculo la dargura do campo receptivo\n",
        "        #2º parâmetro da rede RBF\n",
        "        self.stds = self.computeStds(self.centers,self.k)\n",
        "        # training\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(X.shape[0]):\n",
        "                # forward pass\n",
        "                #calcula a saída de cada neurônio da função de base radial\n",
        "                phi = np.array([self.rbf(X[i], c, s) for c, s, in zip(self.centers, self.stds)])\n",
        "                #calcula somatório do produto da saída da função de base radial e os pesos\n",
        "                F = phi.T.dot(self.w)\n",
        "                F = np.sum(F) + self.b\n",
        "                #saída da rede\n",
        "                out = 0 if F < 0 else 1\n",
        "                \n",
        "                #função de perda \n",
        "                loss = (y[i] - out).flatten() ** 2\n",
        "                #print('Loss: {0:.2f}'.format(loss[0]))\n",
        "\n",
        "                #cálculo do erro\n",
        "                error = (y[i] - out).flatten()\n",
        "                #atualização dos pesos\n",
        "                #3º Parâmetro da rede \n",
        "                self.w = self.w + self.lr * error * phi \n",
        "                self.b = self.b + self.lr * error\n",
        "\n",
        "    #calcula saída da rede RBF com a rede treinada\n",
        "    def predict(self, X):\n",
        "        y_pred = []\n",
        "        error = 0\n",
        "        for i in range(X.shape[0]):\n",
        "            a = np.array([self.rbf(X[i], c, s) for c, s, in zip(self.centers, self.stds)])\n",
        "            F = a.T.dot(self.w)\n",
        "            F = np.sum(F) + self.b\n",
        "            out = 0 if F < 0 else 1\n",
        "            y_pred.append(out)\n",
        "\n",
        "        return np.array(y_pred)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWNpEtxSW46Q"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Isto está formatado como código\n",
        "```\n",
        "\n",
        "# Executando a rede neural RBF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P75CdFJ4W7mU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3031918c-7b89-4ef7-ce51-22840bb20216"
      },
      "source": [
        "# Neste código vou utilizar o pandas, framework amplamente utilizado pra lidar com dados\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#carrega a base de dados e retorna conjuntos de treinamento e teste\n",
        "def load_data():\n",
        "    url = 'redes_neurais_bcc/RBF/wine.csv'\n",
        "    df = pd.read_csv(url)\n",
        "    #remove a ultima coluna (dados)\n",
        "    data = df[df.columns[:-1]]\n",
        "    #normaliza os dados\n",
        "    normalized_data = (data - data.min()) / (data.max() - data.min())\n",
        "    #retorna a última coluna (rótulos)\n",
        "    labels = df[df.columns[-1]]\n",
        "    #separa em conjunto de treinamento e teste com seus respectivos rótulos\n",
        "    X_train, X_test, y_train, y_test = train_test_split(normalized_data, labels, test_size=0.2, random_state=0)\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "#chama função que carrega base de dados\n",
        "training_inputs, test_inputs, training_labels, test_labels = load_data()\n",
        "\n",
        "#transforma rótulos do conjunto de treinamento em numeros pra calculo do erro\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(training_labels.values)\n",
        "training_labels_transformed = le.transform(training_labels.values)\n",
        "\n",
        "#chama RBF\n",
        "rbfnet = RBFNet(lr=1e-2, attnumber=13, k=3, computeStds=computeEqualStds)\n",
        "rbfnet.fit(training_inputs.values, training_labels_transformed)\n",
        "\n",
        "#transforma rótulos do conjunto de teste em numeros pra calculo do erro\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(test_labels.values)\n",
        "test_labels_transformed = le.transform(test_labels.values)\n",
        "\n",
        "y_pred = rbfnet.predict(test_labels_transformed)\n",
        "\n",
        "errorabs = abs(test_labels_transformed-y_pred)\n",
        "\n",
        "print('error: ', np.sum(errorabs)/len(test_labels_transformed))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error:  0.9585798816568047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLO2Gq4Jtso3"
      },
      "source": [
        "# Descrição Mini Projeto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOrl4i0areNo"
      },
      "source": [
        "Utilizando o código acima, modifique a última seção (Executando com Base de Dados) para que ele seja executado com a base de dados do arquivo iris.csv. Depois, modifique a função de base radial implementada (Gaussiana) para a Multiquadrática Inversa e calcule a taxa de erro.\n",
        "\n",
        "\n",
        "1- Calcular a quantidade de neurônios escondidos:\n",
        "\n",
        "a) 3\n",
        "\n",
        "b) 5\n",
        "\n",
        "c) 7\n",
        "\n",
        "d) 9\n",
        "\n",
        "Qual foi a melhor configuração? Avaliaria um outro valor?\n",
        "\n",
        "2- Utilizando a melhor configuração da questão anterior, calcular a taxa de erro usando uma das outras maneiras de retorno da largura do campo receptivo da função de base radial, em que cada neurônio possui sua própria largura. \n",
        "\n",
        "\n",
        "3- Calcular a taxa de erro combinando 2 funções de Base Radial e as duas maneiras de cálculo da largura do campo receptivo:\n",
        "\n",
        "a) Gaussiana\n",
        "\n",
        "b) Multiquadrática Inversa\n",
        "\n",
        "\n",
        "Qual foi a melhor configuração?\n",
        "\n",
        "\n",
        "\n",
        "DATA DE ENTREGA: 25/11/2020\n"
      ]
    }
  ]
}